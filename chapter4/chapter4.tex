%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Chapter 4 -> Experiments
% Author: Mingbo Cheng
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experiments}
\label{chapter:experiments}

\graphicspath{{chapter4/figs}}


\section{Single cell Multi-modal dimensional integration}

\subsection{Multimodal benchmarking data}

We make use of public multimodal data sets with two or tri-modalities in our evaluation.  The first two data sets are single cell cite-seq data which measures single cell RNA and surface proteins simultaneously.  The third and fourth data sets are single cell data which measures single cell RNA and single cell ATAC simultaneously. And the last two data sets are single cell data that simultaneously measure single RNA, single-cell ATAC-seq and single-cell protein.

\begin{table}[!ht]
	\footnotesize
	\centering
	\begin{tabular}{lllllrrp{0.15\linewidth}}
		\toprule
		{\textbf{Dataset}} & {\textbf{Protocol}} & {\textbf{Species}}  &{\textbf{Organ}}  & {\textbf{Modalities}} &{\textbf{\#cells}}  &{\textbf{\#Cell types}}   &{\textbf{\#Features (gene/peak/protein)}} \\ 
		\midrule
		  BM-CITE  & CITE-seq & Human & Bone Marrow & RNA/protein & 30,672  & 27 & 17,009/-/25 \\
		  LUNG-CITE  & CITE-seq & Human & PBMC\&Lung & RNA/protein & 10,470  & 22 & 33,514/-/52 \\
		  PBMC-Multiome  & Multiome & Human  & PBMC & RNA/ATAC & 11,787 & 13 & 36,610/108,377/- \\ 
		  Skin-SHARE  & SHARE-seq & Mouse & Skin & RNA/ATAC & 34,774 & 23 & 23,296/344,592/- \\ 
		  PBMC-TEA  & TEA-seq  & Human & PBMC & RNA/ATAC/epitope & 25,517 & 12 &  36,601/128,853/47\\ 
		  PBMC-DOGMA  & DOGMA-seq & Human & PBMC & RNA/ATAC/protein & 13,763  & 27 & 36,495/68,963/210 \\
		\bottomrule
	\end{tabular}
	\vspace{0.1cm}
	\caption[Major characteristics of multi-modal data sets]{Major characteristics of multi-modal data sets.}
	\label{tab:MOJITOO_DATA}
\end{table}


\begin{description}
	\item[{\texttt{BM-CITE}}]
	The human bone marrow mononuclear cells ({\texttt{BM-CITE}}) data set contains full transcriptomes and 25 surface proteins for over 30,672 cells annotated in 27 cell types~\citep{hao2021seurat4}. This data was obtained with the ``LoadData("bmcite")'' command from the package SeuratData. Next, we applied the ~\hyperref[sec:preproccessing]{pre-processing} pipeline.	

	\item[{\texttt{LUNG-CITE}}]
	Another CITE-seq data used were the human peripheral blood mononuclear cells from the lung ({\texttt{LUNG-CITE}}) ~\citep{buus2021improving} with 52 surface proteins. It contains 10,470 cells annotated in 22 cell types. This data was obtained from ~\url{https://tinyurl.com/253jp4sa}.

	\item[{\texttt{PBMC-multiome}}]
  	The next data set contains human peripheral blood mononuclear cells ({\texttt{PBMC-multiome}}) generated by the 10x multiome technology to measure gene expression (scRNA-seq) and chromatin accessibility (scATAC-seq) on the same cells. This data contains 11,787 cells with 13 cell types annotated by 10X Genomics.  We use the scRNA-seq and scATAC-seq count matrices as provided by 10x genomics after processing with the Cellranger pipeline obtained from the ~\url{https://tinyurl.com/yw229pbf}.

	\item[{\texttt{PBMC-multiome}}]
	We also use a data set based on the SHARE-seq protocol measuring gene expression and chromatin accessibility of mouse skin cells ({\texttt{ SKIN-SHARE}})~\citep{ma2020chromatin}. This data contains 34,774 cells, which are annotated as 23 cell types. We obtain the skin scRNA-seq and scATAC-seq counts and fragments files from the Gene Expression Omnibus under accession number (\href{https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE140203}{GSE140203}).

	\item[{\texttt{PBMC-DOGMA}}]
	A tri-modal data set of human PBMCs is measured with the DOGMA-seq protocol~\citep{mimitou2021scalable}. This provides RNA, ATAC and epitope sequencing of the same cells ({\texttt{PBMC-DOGMA}}). We use data under low-loss lysis conditions, which contains 13,763 cells in 27 cell types. We download count matrices as provided by the authors ~\url{https://osf.io/6kr4v/}.

	\item[{\texttt{PBMC-TEA}}]
	A second tri-modal dataset is based on human PBMCs measured with the TEA-seq protocol~\citep{swanson2021simultaneous}. It contains transcripts, epitopes and chromatin accessibility of 25,517 PBMCs grouped into 12 cell types ({\texttt{PBMC-TEA}}). For this data set, we obtain original matrices and combine data from distinct wells from GEO (GSE158013). For scATAC-seq, we obtain an integrated matrix by combing peaks (allowing an extension of Â±250bps). We finally intersect all barcodes from scRNA-seq, protein and scATAC-seq to obtain matrices in the same cell space. Characteristics of each of the six data sets are described in ~\tref{tab:MOJITOO_DATA}.


\end{description}

%\begin{table*}
%\footnotesize
%\centering
% \caption{Major characteristics of multi-modal data sets.}
%  \label{tab:data}
%\begin{tabular}{ | l | l | l | l | l | r | r | p{0.15\linewidth} | } 
%  \hline
%  {\textbf{Dataset}} & {\textbf{Protocol}} & {\textbf{Species}}  &{\textbf{Organ}}  & {\textbf{Modalities}} &{\textbf{\#cells}}  &{\textbf{\#Cell types}}   &{\textbf{\#Features (gene/peak/protein)}} \\ 
%  \hline
%  BM-CITE  & CITE-seq & Human & Bone Marrow & RNA/protein & 30,672  & 27 & 17,009/-/25 \\
%  \hline
%  LUNG-CITE  & CITE-seq & Human & PBMC\&Lung & RNA/protein & 10,470  & 22 & 33,514/-/52 \\
%  \hline
%  PBMC-Multiome  & Multiome & Human  & PBMC & RNA/ATAC & 11,787 & 13 & 36,610/108,377/- \\ 
%  \hline
%  Skin-SHARE  & SHARE-seq & Mouse & Skin & RNA/ATAC & 34,774 & 23 & 23,296/344,592/- \\ 
%  \hline
%  PBMC-TEA  & TEA-seq  & Human & PBMC & RNA/ATAC/epitope & 25,517 & 12 &  36,601/128,853/47\\ 
%  \hline
%  PBMC-DOGMA  & DOGMA-seq & Human & PBMC & RNA/ATAC/protein & 13,763  & 27 & 36,495/68,963/210 \\
%  \hline
%\end{tabular}
%\end{table*}




\subsection{Execution of single cell multi-modal integration data}
% List how to install and run the competing methods
\subsubsection{competing methods}
%% TODO: need split these into two parts: algorithm(chapter2) and execution(chapter4).
\begin{description}
\item[MOFA] 
We install MOFA2(1.2.2)\citep{tewari2017mofa} \href{from https://github.com/bioFAM/MOFA2} R CMD INSTALL MOFA2. Next, We execute MOFA with default parameters and follow their recommendations  \href{https://raw.githack.com/bioFAM/MOFA2_tutorials/master/R_tutorials/10x_scRNA_scATAC.html}{tutorial} for the analysis of all data. However, we provide now PCA/LSI reductions as input for MOFA, as this improved its computational time (Appendix ~\tref{tab:time}), as well the clustering performance on MOFA's latent space (Appendix Fig.~2). 

\item[Schema]
``pip install schema\_learn'' under the python==3.9.6 environment
Schema(0.1.5.3)~\cite{singh2021schema} explores metrics learning to re-weigh modality features through maximizing the agreement with other modalities. Specifically, it utilizes quadratic programming (QP) to learn a scaling transformation $u$ for the primary matrix $X$ such that pairwise distances of the transformation $u *  x_i$ (where $*$ is coordinate-wise multiplication, for each $x_i\in X$) are highly correlated in other modalities. Schema has two main parameters: minimum desired correlation and number of random pairs.  We run Schema using default parameters as in 
\href{https://schema-multimodal.readthedocs.io/en/latest/recipes/index.html}{schema tutorial.} 

\item[Seurat4 WNN]
install Seurat(4.3.0) using remotes::install\_version(``Seurat'', version = ``4.3.0'') in R(4.1.0) prompt.
Weighted nearest neighbor (WNN)~\cite{hao2021seurat4} constructs single unified representation across multiple modalities. It first creates k-nearest neighbor (KNN) graphs for each modality based on the latent representation of each feature matrix.  Next, it calculates affinities using the exponential kernel between a cell and the average NN for each modality. The latter is used to weigh cells.  WNN has two major free parameters: the number of neighbors and scaling factor of the neighborhood kernel. We execute WNN, which is part of Seurat4, using default parameters. WNN does not provide a shared latent space, but we can use the weighted nearest neighbors graph to build a distance metric that can be used in all benchmarking evaluations.

\item[scAI]
install scAI(1.0.0) using devtools::install\_github(``sqjin/scAI'') in R prompt.
 simultaneously decomposes transcriptomic and epigenomic data into multiple biologically relevant factors~\cite{clark2018scnmt}. Its framework is similar to MOFA, but it can only cope with two modalities at a time. scAI uses a stability method to define the rank (size of the latent space) and has three main free parameters used for model regularization. We execute scAI in only bi-modal with RNA and ATAC-seq datasets with default parameters.


\item[LIGER]

install rliger(1.0.0) using R install.packages(``rliger'') in R prompt.
LIGER~\cite{welch2019single}, which is based on non-negative matrix factorization, was originally proposed for data integration whenever modalities are in the same feature space.  A newer variant of LIGER~\cite{kriebel2021nonnegative} can perform integration, whenever there is some overlap between the features across modalities (shared features), i.e. protein and RNA expression of the same gene or gene accesibility scores for ATAC-seq. LIGER estimates a gene accessibility (ATAC-seq) matrix by counting the total number of ATAC-seq reads within the gene body and promoter regions(3kb upstream) for each gene per cell. An additional unshared feature matrix is further produced by binning the genome into bins of 100,000 bps and counting the overlap of these bins with peaks from the respective data set. LIGER has two major parameters: a regularization term and the number of factors (dimensions of the latent space). Regions associated to ENCODE Blacklist regions~\cite{amemiya2019encode} are removed. Moreover, LIGER can be only executed for bi-modal data sets. 

\item[Symphony Integration]
The CCA analysis is not part of Symphony~\cite{kang2021symphony} source code, we implemented it based on a script provided by authors (\url{https://github.com/immunogenomics/TB_Tcell_CITEseq/blob/main/R/cca_analysis.R}). 
Also, due to high computational requirements, we were only able to run this on the dimension-reduced space (PCA/LSI) described above. We call this method Symph-Int to reflect the fact that this is not Symphony, but an integration method used in one of the analyses of Symphony manuscript. 

\item[DIABLO]
We install mixOmics(6.16.3) using bioconductor with BiocManager::install(``mixOmics'') in R prompt.
DIABLO~\cite{singh2019diablo} is based on a generalized canonical analysis to integrate multiple data sets in a supervised way. It was originally designed for bulk multi-omics data, where sample labels are available and explored for feature selection. Since labels are not available for single cell multi-modal data evaluated here, we provide a distinct label for each cell. DIABLO is executed as indicated in their \href{http://mixomics.org/mixdiablo/}{tutorial}. Due to a prohibitive computational costs if raw matrices are used, we provide dimension reduced matrices as input.  Another major parameter is the number of CC components, which is usually set to the number of classes - 1. Here, we used 30 components. Also, DIABLO does not provide a common latent space. We therefore used the same strategy to combine latent spaces as for MOJITOO. 
\end{description}


\subsection{Evaluation of multi-modal integration Methods}
We describe single cell multi-modal for technical validation.

\subsubsection{technical validation}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.95\textwidth]{evaluation_MOJITOO/fig}
	\vspace{0.1cm}
	\caption[evaluation\_MOJITOO]{
	evaluation\_MOJITOO.}
	\label{fig:evaluation_MOJITOO}
\end{figure}

\begin{description} %%formula
	\item[Space Presevation] The high-dimensional space preserves of each dataset can be calculated as the Pearson correlation between all pairwise distances in the high-dimensional spaces and the corresponding distances in the original space~\citep{jain2021multimap}. For multimodal data, space-preserved scores can be obtained for each modality, and these individual scores are then averaged to derive the final space-preserved score.
	\item[Distance Accuracy]. 
  silhouette to latent space to evaluate the performance of these methods. For each data point $i\in C_i$, where $C_i$ is the label of the data point, we calculate the inner cluster mean distance:
\begin{equation}
  a(i) = \frac{1}{|C_i| - 1} \underset{j \in c_i, i\neq j}{\sum} d(i, j)
\end{equation}
Next, the smallest mean out cluster distance to data point $i$ is:
\begin{equation}
b(i) = \underset{k\neq i}{\min}\frac{1}{|C_k|}\underset{j\in c_k}{\sum} d(i,j)
\end{equation}
The solhoutte index is defined as:
\begin{equation}
s(i)=\frac{b(i)-a(i)}{\max\{a(i), b(i)\}}, -1\leq s(i) \leq 1
\end{equation}
where $d(i,j)$ is the distance of two cells under some specific latent space, here we considered both euclidean distance and cosine distance.

	\item[Clustering Accuracy] Clustering Accuracy measure the clustering accuracy compared to the true labels using different integrated embeddings. In comparing the clustering outcomes with labels from benchmarking datasets, we employed the adjusted rand index (ARI)\citep{hubert1985ARI}. This index assesses the similarity between two clustering results by accounting for the likelihood of randomly grouping elements. Specifically, given a dataset $D$ with $n$ cells, two partitions $ X = \{ X_{1}, X_{2}, \cdots X_{r} \} $ and $ Y = \{ Y_{1}, Y_{2}, \cdots, Y_{s} \} $ denoting different clustering results, the number of common cells for each cluster $i$ and $j$ can be written as $n_{ij} = X_{i} \cap Y_{j} |$, where $ i \in \{1, 2, \cdots, r \} $ and $ j \in \{1, 2, \cdots, s \} $. Then Adjusted Rand Index(ARI) is denoted as follows:
	\begin{equation}
		ARI = \frac{\sum_{ij} {n_{ij} \choose 2} - [ \sum_{i} {a_{i} \choose 2} \sum_{j} {b_{j} \choose 2 } ] / {n \choose 2}}{\frac{1}{2} [\sum_{i} {a_{i} \choose 2 } + \sum_{j} {b_{j} \choose 2}] - [\sum_{i} {a_{i} \choose 2} \sum_{j} {b_{j} \choose 2 } ] / {n \choose 2} }
	\end{equation}
	where $ a_{i} = \sum_{j=1}^{s} n_{ij} $ and $ b_{j} = \sum_{i=1}^{r} n_{ij} $ respectively. The ARI ranges from a minimum value of 0, denoting random agreement between two data clusterings, to a maximum value of 1, indicating identical clustering results.  To be fair, we perform Louvain clustering with varying resolution (parameter from 0.1 to 2.0 with step=0.1) to estimate the adjusted Rand index. 
	\item[Requirements of Memory and Running Time] We also compare the peak memory usage and running time to check the effectiveness of these methods. For this, we inspect the time and memory used in the largest datasets in our benchmark (SKIN-SHARE). To obtain curves, we down-sample the number of cells from 30,000 to 3,000.
\end{description}

% to validate improve the perfomance, ---> PBMC capture major cell types and subtype changings
\subsection{Biological Validatation}


\subsection{Statistical methods}
% Nemenyi post-hoc test
\subsection{Discussion}


\section{Single cell trajectory inference}

\subsection{Simulated Data}
\subsection{Execution of trajectory inference}
% List how to install and run the competing methods
% how to set up dynverse environment
\subsubsection{competing methods}
	We first, install dyno(0.1.2) which includes some competing methods of wrapping. To do this, we use devtools::install\_github(``dynverse/dyno'') which includes the dynverse packages dynwrap(1.2.3),  dynmethods(1.0.5.9000), dynplot(1.1.2) and dynfeature(1.0.0). For PHLOWER and STREAM wrapping, we followed tutorial ~\url{https://dynverse.org/developers/creating-ti-method/}. For this, we clone dynclipy(0.1) code from ~\url{https://github.com/dynverse/dynclipy} and use ``pip install .'' to install the package.
\begin{description}
	\item[PHLOWER]
	We need use 
	\item[TSCAN]
	TSCAN has been wrapped in dynwmethods, we just pass the ti\_tscan function to dynwrap function infer\_trajectory to infer the trajectory. source code is ~\url{https://github.com/dynverse/ti\_tscan}
	\item[STREAM]
	\item[PAGA] 
	PAGA has been wrapped in dynwmethods, we just pass ti\_paga\_tree function to dynwrap function infer\_trajectory to infer the trajectory. source code is ~\url{https://github.com/dynverse/ti\_paga\_tree}
	\item[Monocle3]
	Monocle3 has been wrapped in dynwmethods, we just pass the ti\_monocle3 function to dynwrap function infer\_trajectory to infer the trajectory. source code is ~\url{https://github.com/dynverse/ti\_monocle3}
	\item[Slingshot]
	Slingshot has been wrapped in dynwmethods, we just pass ti\_slingshot function to dynwrap function infer\_trajectory to infer the trajectory. source code is ~\url{https://github.com/dynverse/ti\_slingshot}
	\item[Slicer]
	xxx
	\item[slice]
	Slice has been wrapped in dynwmethods in ~\url{https://github.com/dynverse/ti\_slice}. However, the simulated data need not log transformation, we adjust ti\_slice code to exclude the transformation part i.e. set ``expression <- exp(expression) - 1'' to be a new wrapper method\_slice. And pass method\_slice function to dynwrap function infer\_trajectory to infer the trajectory.
	\item[RaceID/StemID]
	RaceID/StemID has been wrapped in dynwmethods in ~\url{https://github.com/dynverse/ti\_raceid\_stemid}. However, it needs positive input, we adjust ti\_raceid\_stemid code to scale the input data to 0-10 to be a new wrapper method\_raceid\_stemid. And pass method\_raceid\_stemid function to dynwrap function infer\_trajectory to infer the trajectory.
	\item[MST] 
	Minimum spanning tree(MST) is implemented in R package mclust.
	\item[ElPiGraph] 
	ElPigraph has been wrapped in dynwmethods, we just pass the ti\_elpigraph function to dynwrap function infer\_trajectory to infer the trajectory. source code is ~\url{https://github.com/dynverse/ti_elpigraph}
	\item[celltree] 
	celltree has been wrapped in dynwmethods in ~\url{https://github.com/dynverse/ti\_celltree\_vem}. However, the cellTree source code normalization function ``.normalise.data'' would not work with negative values. We check out cellTree(1.27.0) source code from ~\url{https://git.bioconductor.org/packages/cellTree} and adjust the ``.normalise.data'' function to use 0-1 normalization as the data output for the downstream inference process and recompile cellTree package as the input of dynmethods wrapper. We re-wrap ti\_celltree\_vem code to use the call new cellTree package to be a new wrapper method\_celltree\_vem. And pass method\_celltree\_vem function to dynwrap function infer\_trajectory to infer the trajectory.
	\item[pCreode] 
	pCreode has been wrapped in dynwmethods, we just pass the ti\_pcreode function to dynwrap function infer\_trajectory to infer the trajectory. source code is ~\url{https://github.com/dynverse/ti\_pcreode}
\end{description}

\subsection{Evaluation of trajectory inference}
% dynverse benchmarking selected metrics description
The simulated data for trajectory inference. We first described the data source and pre-processing for single cell multi-modal data, next we show how to simulate data for trajectory inference.
\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.95\textwidth]{dynverse_metrics/fig}
	\vspace{0.1cm}
	\caption[dynverse\_metrics]{
	dynverse\_metrics.}
	\label{fig:dynverse_metrics}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.95\textwidth]{evaluation_PHLOWER/fig}
	\vspace{0.1cm}
	\caption[evaluation\_PHLOWER]{
	evaluation\_PHLOWER.}
	\label{fig:evaluation_PHLOWER}
\end{figure}


\subsection{Apply integration \& trajectory inference to kidney organoid data}
\subsection{Characterize the cell fate xxxx}
\subsection{Discussion}

